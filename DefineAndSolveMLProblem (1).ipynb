{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) I have chosen the book review data set\n",
    "2) I will be predicting whether a review is positive or negative by doing a sentiment analysis prediction for binary classification. The label will be 'positive review'\n",
    "3) This is a classification problem, specifically binary classification. This is a supervised learning problem.\n",
    "4) The feature is just 'review'\n",
    "5) This is important because we can gain insight into customer satisfaction and companies can see which books are receiving negative or positive feedback. They can tend to the positive ratings by promoting these books as a marketing strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values?:\n",
      " Review             0\n",
      "Positive Review    0\n",
      "dtype: int64\n",
      "(rows, cols) :  (1973, 2)\n",
      "                                                   Review Positive Review\n",
      "count                                                1973            1973\n",
      "unique                                               1865               2\n",
      "top     I have read several of Hiaasen's books and lov...           False\n",
      "freq                                                    3             993\n",
      "\n",
      " Review             object\n",
      "Positive Review      bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#Inspecting and analyzing data\n",
    "print(\"Missing values?:\\n\", df.isna().sum())\n",
    "print(\"(rows, cols) : \", df.shape)\n",
    "print(df.describe()) #mostly False reviews\n",
    "print('\\n', df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data?Â \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The features I chose is 'Review.' After text-preprocessing, the new feature will be 'processed review' which contains the review after performing text-preprocessing. \n",
    "2) I will perform text preprocessing techniques such as lowercasing, removing punctuation, tokenization, stop words removal, and stemming. Then I'll perform feature engineering such as TF-IDF vectorization. I will improving on my model by performing hyperparameter tuning and finding the best threshold. \n",
    "3) I will be doing a logistic regression model with default parameters first and then perform ways to optimize the model. I will specifically be looking at improved F1 scores and AUC scores. \n",
    "4) After performing text preprocessing techniques and feature engineering, I will also do hyperparameter tuning and using the best threshold to ensure that the model generalizes well on different subsets of the data.\n",
    "\n",
    "F1 score: a metric used in machine learning to evaluate binary classification models. It is a harmonic mean of precision and recall. \n",
    "AUC: a single number that measures a classifier's performance across all possible classification thresholds.\n",
    "Logistic Regression Model: a supervised machine learning algorithm used for classification tasks where the goal is to predict the probability that an instance belongs to a given class or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "      <th>Processed Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "      <td>best johann steinhoff book do deal stellar tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "      <td>fascinat book story written form numerou lette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "      <td>tal collection beautiful compos art just stori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "      <td>book contain profanity expect read book rita r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "      <td>enter second time deep concern science math te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review  \\\n",
       "0  This was perhaps the best of Johannes Steinhof...             True   \n",
       "1  This very fascinating book is a story written ...             True   \n",
       "2  The four tales in this collection are beautifu...             True   \n",
       "3  The book contained more profanity than I expec...            False   \n",
       "4  We have now entered a second time of deep conc...             True   \n",
       "\n",
       "                                    Processed Review  \n",
       "0  best johann steinhoff book do deal stellar tra...  \n",
       "1  fascinat book story written form numerou lette...  \n",
       "2  tal collection beautiful compos art just stori...  \n",
       "3  book contain profanity expect read book rita r...  \n",
       "4  enter second time deep concern science math te...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining a stemming function\n",
    "def stemming(word):\n",
    "    suffixes = ['ing', 'ed', 'es', 's', 'er', 'ly']\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "# Defining text preprocessing function for tokens\n",
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = text.split()  # splitting on whitespace\n",
    "    \n",
    "    # Convert tokens to lowercase and remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [token.lower().translate(table) for token in tokens]\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    # Stemming tokens using stemmer function\n",
    "    tokens = [stemming(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "    \n",
    "df['Processed Review'] = df['Review'].apply(preprocess_text) #adding a new review text-preprocessed column \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Processed Review'] #new review/feature column after text preprocessing\n",
    "y = df['Positive Review'] #label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 16338: \n",
      "[('reason', 11977), ('book', 1944), ('sold', 13583), ('180000', 83), ('copi', 3365), ('get', 6229), ('right', 12502), ('point', 11035), ('accompani', 461), ('strategy', 14002), ('visual', 15663), ('aid', 697), ('mental', 9137), ('picture', 10896), ('head', 6747), ('section', 12980), ('analyz', 891), ('stock', 13952), ('commentary', 2991), ('state', 13871), ('financial', 5653), ('statement', 13873), ('market', 8911), ('money', 9465), ('just', 8032), ('start', 13862), ('option', 10250), ('real', 11959), ('th', 14545), ('cookbook', 3350), ('author', 1377), ('learn', 8346), ('cook', 3349), ('recip', 12003), ('techniqu', 14440), ('know', 8175), ('heart', 6766), ('pam', 10495), ('anderson', 906), ('bigbreast', 1770), ('art', 1188), ('high', 6879), ('marketable', 8912), ('title', 14767), ('starter', 13864), ('artful', 1191), ('monik', 9471), ('play', 10980), ('single', 13376), ('gal', 6081)]\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#feature stage\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()#tranforms text data into numerical features\n",
    "\n",
    "# Fit and transform the data\n",
    "tfidf_vectorizer.fit(X_train) #process text data to create vocab of words and their corresponding index\n",
    "\n",
    "print(\"Vocabulary size {0}: \".format(len(tfidf_vectorizer.vocabulary_)))\n",
    "print(str(list(tfidf_vectorizer.vocabulary_.items())[0:50])+'\\n')\n",
    "\n",
    "# Convert the matrix to a DataFrame for easier visualization\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# 5. Print the matrix\n",
    "print(X_train_tfidf.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Logistic Regression model...\n",
      "Initial AUC on the test data: 0.9033\n",
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.81      0.81       237\n",
      "        True       0.83      0.82      0.83       257\n",
      "\n",
      "    accuracy                           0.82       494\n",
      "   macro avg       0.82      0.82      0.82       494\n",
      "weighted avg       0.82      0.82      0.82       494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. initial Logistic Regression model\n",
    "#uses default hyperparameters, except max_iter = 200 \n",
    "#trains a logistic regression model\n",
    "print(\"Initial Logistic Regression model...\")\n",
    "model1 = LogisticRegression(max_iter=200)\n",
    "model1.fit(X_train_tfidf, y_train) \n",
    "\n",
    "initial_prob_predictions = model1.predict_proba(X_test_tfidf)[:, 1] #gives probability estimates of label\n",
    "initial_class_label_predictions = model1.predict(X_test_tfidf) #provides binary class predicitons\n",
    "\n",
    "initial_auc = roc_auc_score(y_test, initial_prob_predictions) #evaluate model's performance using AUC, measures model's ability to distinguish between classes\n",
    "print('Initial AUC on the test data: {:.4f}'.format(initial_auc))\n",
    "\n",
    "print('Initial Classification Report:')\n",
    "print(classification_report(y_test, initial_class_label_predictions)) #provides precision, recall, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Best Threshold: 0.4747474747474748\n",
      "Initial Best F1 Score: 0.8379888268156425\n",
      "Initial Classification Report with optimized threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.77      0.81       237\n",
      "        True       0.80      0.88      0.84       257\n",
      "\n",
      "    accuracy                           0.82       494\n",
      "   macro avg       0.83      0.82      0.82       494\n",
      "weighted avg       0.83      0.82      0.82       494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimize threshold for the initial LR model\n",
    "initial_thresholds = np.linspace(0, 1, 100) #creates 100 evenly spaces thresholds 0-1\n",
    "initial_f1 = 0\n",
    "initial_threshold = 0\n",
    "\n",
    "for threshold in initial_thresholds:\n",
    "    predictions = (initial_prob_predictions >= threshold).astype(int) #applies each threshold to create binary predictions\n",
    "    current_f1 = f1_score(y_test, predictions) #computes F1 score for each threshold\n",
    "    if current_f1 > initial_f1:\n",
    "        initial_f1 = current_f1\n",
    "        initial_threshold = threshold\n",
    "\n",
    "final_initial_predictions = (initial_prob_predictions >= initial_threshold).astype(int)\n",
    "print(f'Initial Best Threshold: {initial_threshold}')\n",
    "print(f'Initial Best F1 Score: {initial_f1}')\n",
    "print('Initial Classification Report with optimized threshold:')\n",
    "print(classification_report(y_test, final_initial_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing hyperparameter tuning with GridSearchCV...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized AUC on the test data: 0.9036\n",
      "Optimized Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.81      0.81       237\n",
      "        True       0.83      0.82      0.82       257\n",
      "\n",
      "    accuracy                           0.82       494\n",
      "   macro avg       0.82      0.82      0.82       494\n",
      "weighted avg       0.82      0.82      0.82       494\n",
      "\n",
      "Optimized Best Threshold: 0.4747474747474748\n",
      "Optimized Best F1 Score: 0.8379888268156425\n",
      "Optimized Classification Report with optimized threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.77      0.81       237\n",
      "        True       0.80      0.88      0.84       257\n",
      "\n",
      "    accuracy                           0.82       494\n",
      "   macro avg       0.83      0.82      0.82       494\n",
      "weighted avg       0.83      0.82      0.82       494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Perform hyperparameter tuning\n",
    "print(\"Performing hyperparameter tuning with GridSearchCV...\")\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "} #defines grid of hyperparameters to search over\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(max_iter=200),\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1) #trains a model using cross-validation\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "model2 = grid_search.best_estimator_ #gets logistic regression model with best hyperparameter\n",
    "best_predictions = model2.predict_proba(X_test_tfidf)[:, 1]\n",
    "best_class_label_predictions = model2.predict(X_test_tfidf)\n",
    "\n",
    "best_auc = roc_auc_score(y_test, best_predictions)\n",
    "print('Optimized AUC on the test data: {:.4f}'.format(best_auc))\n",
    "\n",
    "print('Optimized Classification Report:')\n",
    "print(classification_report(y_test, best_class_label_predictions))\n",
    "\n",
    "# Optimize threshold for the optimized model\n",
    "optimized_thresholds = np.linspace(0, 1, 100)\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in optimized_thresholds:\n",
    "    predictions = (best_predictions >= threshold).astype(int)\n",
    "    curr_f1 = f1_score(y_test, predictions)\n",
    "    if curr_f1 > best_f1:\n",
    "        best_f1 = curr_f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "final_predictions = (best_predictions >= best_threshold).astype(int)\n",
    "print(f'Optimized Best Threshold: {best_threshold}')\n",
    "print(f'Optimized Best F1 Score: {best_f1}')\n",
    "print('Optimized Classification Report with optimized threshold:')\n",
    "print(classification_report(y_test, final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the index of the review you want to analyze:  56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #57:\n",
      "\n",
      "Is that those who read it and believe it, believe they actualy have girlfriends!!! Come on! admit it you are guys who wear black sabbath t-shirts and live in your parents basements. You also believe that you can get control of you live by chanting some spells from a book made to get your money.  Look, go get a hair cut, take a bath and loose 10 pounds and you will probably get that girl friend that you talk about.  Oh by the way the Necronomicon is fiction! . . except for the real copy that is in my basement, in my parents house where I used to live when I was 15\n",
      "\n",
      "\n",
      "Prediction (initial model): Is this a good review? True\n",
      "\n",
      "Prediction (optimized model): Is this a good review? True\n",
      "\n",
      "Actual: Is this a good review? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt user to pick a review to analyze\n",
    "def search_review(index):\n",
    "    try:\n",
    "        # Ensure the index is valid\n",
    "        if index < 0 or index >= len(df):\n",
    "            print(\"Invalid Index.\")\n",
    "            return\n",
    "        \n",
    "        print('Review #{}:\\n'.format(index + 1))\n",
    "        print(df.iloc[index]['Review'])  # Print the original review\n",
    "\n",
    "        print('\\nPrediction (initial model): Is this a good review? {}\\n'.format(initial_class_label_predictions[index]))\n",
    "        print('Prediction (optimized model): Is this a good review? {}\\n'.format(best_class_label_predictions[index]))\n",
    "\n",
    "        print('Actual: Is this a good review? {}\\n'.format(y_test.iloc[index]))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Ask the user for the review \n",
    "try:\n",
    "    user_index = int(input(\"Enter the index of the review you want to analyze: \"))\n",
    "    search_review(user_index)\n",
    "except ValueError:\n",
    "    print(\"Invalid index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
